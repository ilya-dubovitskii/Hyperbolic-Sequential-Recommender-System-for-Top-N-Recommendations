{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Variational Autoencoders for Collaborative Filtering\n",
    "\n",
    "**Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, and Vikram Pudi** - *12th International ACM Conference on Web Search and Data Mining - WSDM '19*\n",
    "\n",
    "The notebook provides PyTorch code for the proposed model, \"SVAE\" along with the data preprocessing for the Movielens-1M dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-23 15:23:24--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5917549 (5.6M) [application/zip]\n",
      "Saving to: ‘ml-1m.zip’\n",
      "\n",
      "ml-1m.zip           100%[===================>]   5.64M  1.66MB/s    in 3.4s    \n",
      "\n",
      "2022-02-23 15:23:28 (1.66 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "!wget --no-check-certificate https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip -q  ml-1m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change `DATA_DIR` to the location where the dataset sits\n",
    "### compatible datasets: ML-1M, Netflix-full\n",
    "\n",
    "hyper_params = {\n",
    "    'data_base': 'ml-1m/', # Don't remove the '/' at the end please :)\n",
    "    'project_name': 'svae_ml1m',\n",
    "    # 'data_base': 'saved_data/netflix-full/',\n",
    "    # 'project_name': 'svae_netflix_full',\n",
    "    'model_file_name': '',\n",
    "    'log_file': '',\n",
    "    'history_split_test': [0.8, 0.2], # Part of test history to train on : Part of test history to test\n",
    "\n",
    "    'learning_rate': 0.01, # learning rate is required only if optimizer is adagrad\n",
    "    'optimizer': 'adam',\n",
    "    'weight_decay': float(5e-3),\n",
    "\n",
    "    'epochs': 25,\n",
    "    'batch_size': 1, # Needs to be 1, because we don't pack multiple sequences in the same batch\n",
    "    \n",
    "    'item_embed_size': 256,\n",
    "    'rnn_size': 200,\n",
    "    'hidden_size': 150,\n",
    "    'latent_size': 64,\n",
    "    'loss_type': 'predict_next', # [predict_next, same, prefix, postfix, exp_decay, next_k]\n",
    "    'next_k': 1,\n",
    "\n",
    "    'number_users_to_keep': 1_000_000_000,\n",
    "    'batch_log_interval': 1000,\n",
    "    'train_cp_users': 200,\n",
    "    'exploding_clip': 0.25,\n",
    "}\n",
    "\n",
    "file_name = '_optimizer_' + str(hyper_params['optimizer'])\n",
    "if hyper_params['optimizer'] == 'adagrad':\n",
    "    file_name += '_lr_' + str(hyper_params['learning_rate'])\n",
    "file_name += '_weight_decay_' + str(hyper_params['weight_decay'])\n",
    "file_name += '_loss_type_' + str(hyper_params['loss_type'])\n",
    "file_name += '_item_embed_size_' + str(hyper_params['item_embed_size'])\n",
    "file_name += '_rnn_size_' + str(hyper_params['rnn_size'])\n",
    "file_name += '_latent_size_' + str(hyper_params['latent_size'])\n",
    "\n",
    "log_file_root = \"saved_logs/\" # Don't remove the '/' at the end please :)\n",
    "model_file_root = \"saved_models/\" # Don't remove the '/' at the end please :)\n",
    "\n",
    "if not os.path.isdir(log_file_root): os.mkdir(log_file_root)\n",
    "if not os.path.isdir(model_file_root): os.mkdir(model_file_root)\n",
    "hyper_params['log_file'] = log_file_root + hyper_params['project_name'] + '_log' + file_name + '.txt'\n",
    "hyper_params['model_file_name'] = model_file_root + hyper_params['project_name'] + '_model' + file_name + '.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "**Courtesy:** Dawen Liang et al. \"*Variational autoencoders for collaborative filtering*\" published at WWW '18. <br>\n",
    "**Link:** https://github.com/dawenl/vae_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = hyper_params['data_base']\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg') # Path where preprocessed data will be saved\n",
    "hyper_params['data_base'] += 'pro_sg/'\n",
    "\n",
    "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
    "    cols = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "    dtypes = {'userId': 'int', 'movieId': 'int', 'timestamp': 'int', 'rating': 'int'}\n",
    "    raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.dat'), sep='::', names=cols, parse_dates=['timestamp'])\n",
    "\n",
    "    max_seq_len = 1000\n",
    "    n_heldout_users = 750 # If total users = N; train_users = N - 2*heldout; test_users & val_users = heldout\n",
    "\n",
    "    # binarize the data (only keep ratings >= 4)\n",
    "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
    "\n",
    "    # Remove users with greater than $max_seq_len number of watched movies\n",
    "    raw_data = raw_data.groupby([\"userId\"]).filter(lambda x: len(x) <= max_seq_len)\n",
    "\n",
    "    # Sort data values with the timestamp\n",
    "    raw_data = raw_data.groupby([\"userId\"]).apply(lambda x: x.sort_values([\"timestamp\"], ascending = True)).reset_index(drop=True)\n",
    "\n",
    "    raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount[itemcount['size'] >= min_sc]['movieId'])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_sc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount[usercount['size'] >= min_uc]['userId'])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount\n",
    "\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (uid, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "#         print(f'uid:{uid}, n_items_u:{n_items_u}')\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            # idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "            idx[int((1.0 - test_prop) * n_items_u):] = True\n",
    "            # print(idx)\n",
    "            \n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te\n",
    "\n",
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    ra = list(map(lambda x: x, tp['rating']))\n",
    "    ret =  pd.DataFrame(data={'uid': uid, 'sid': sid, 'rating': ra}, columns=['uid', 'sid', 'rating'])\n",
    "    ret['rating'] = ret['rating'].apply(pd.to_numeric)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(pro_dir): # We don't want to keep preprocessing every time we run the notebook\n",
    "\n",
    "    raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
    "\n",
    "    sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "    print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "          (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
    "\n",
    "    unique_uid = user_activity.index\n",
    "\n",
    "    np.random.seed(98765)\n",
    "    idx_perm = np.random.permutation(unique_uid.size)\n",
    "    unique_uid = unique_uid[idx_perm]\n",
    "\n",
    "    # create train/validation/test users\n",
    "    n_users = unique_uid.size\n",
    "\n",
    "    tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "    vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "    te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "\n",
    "    train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]\n",
    "\n",
    "    unique_sid = pd.unique(train_plays['movieId'])\n",
    "\n",
    "    show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "    profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "\n",
    "    if not os.path.exists(pro_dir):\n",
    "        os.makedirs(pro_dir)\n",
    "\n",
    "    with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "        for sid in unique_sid:\n",
    "            f.write('%s\\n' % sid)\n",
    "\n",
    "    vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "    vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]\n",
    "\n",
    "    vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
    "\n",
    "    test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "    test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]\n",
    "\n",
    "    test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
    "\n",
    "    train_data = numerize(train_plays)\n",
    "    train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
    "\n",
    "    vad_data_tr = numerize(vad_plays_tr)\n",
    "    vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
    "\n",
    "    vad_data_te = numerize(vad_plays_te)\n",
    "    vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
    "\n",
    "    test_data_tr = numerize(test_plays_tr)\n",
    "    test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
    "\n",
    "    test_data_te = numerize(test_plays_te)\n",
    "    test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utlity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LongTensor = torch.LongTensor\n",
    "FloatTensor = torch.FloatTensor\n",
    "\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda_available: \n",
    "    print(\"Using CUDA...\\n\")\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "    \n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def save_obj_json(obj, name):\n",
    "    with open(name + '.json', 'w') as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_obj_json(name):\n",
    "    with open(name + '.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def file_write(log_file, s):\n",
    "    print(s)\n",
    "    f = open(log_file, 'a')\n",
    "    f.write(s+'\\n')\n",
    "    f.close()\n",
    "\n",
    "def clear_log_file(log_file):\n",
    "    f = open(log_file, 'w')\n",
    "    f.write('')\n",
    "    f.close()\n",
    "\n",
    "def pretty_print(h):\n",
    "    print(\"{\")\n",
    "    for key in h:\n",
    "        print(' ' * 4 + str(key) + ': ' + h[key])\n",
    "    print('}\\n')\n",
    "    \n",
    "def plot_len_vs_ndcg(len_to_ndcg_at_100_map):\n",
    "    \n",
    "    lens = list(len_to_ndcg_at_100_map.keys())\n",
    "    lens.sort()\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for le in lens:\n",
    "        X.append(le)\n",
    "        ans = 0.0\n",
    "        for i in len_to_ndcg_at_100_map[le]: ans += float(i)\n",
    "        ans = ans / float(len(len_to_ndcg_at_100_map[le]))\n",
    "        Y.append(ans * 100.0)\n",
    "    \n",
    "    # Smoothening\n",
    "    Y_mine = []\n",
    "    prev_5 = []\n",
    "    for i in Y:\n",
    "        prev_5.append(i)\n",
    "        if len(prev_5) > 5: del prev_5[0]\n",
    "\n",
    "        temp = 0.0\n",
    "        for j in prev_5: temp += float(j)\n",
    "        temp = float(temp) / float(len(prev_5))\n",
    "        Y_mine.append(temp)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(X, Y_mine, label='SVAE')\n",
    "    plt.xlabel(\"Number of items in the fold-out set\")\n",
    "    plt.ylabel(\"Average NDCG@100\")\n",
    "    plt.title(hyper_params['project_name'])\n",
    "    if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
    "    plt.savefig(\"saved_plots/seq_len_vs_ndcg_\" + hyper_params['project_name'] + \".pdf\")\n",
    "\n",
    "    leg = plt.legend(loc='best', ncol=2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(hyper_params):\n",
    "    \n",
    "    file_write(hyper_params['log_file'], \"Started reading data file\")\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'train.csv')\n",
    "    lines_train = f.readlines()[1:]\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'validation_tr.csv')\n",
    "    lines_val_tr = f.readlines()[1:]\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'validation_te.csv')\n",
    "    lines_val_te = f.readlines()[1:]\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'test_tr.csv')\n",
    "    lines_test_tr = f.readlines()[1:]\n",
    "    \n",
    "    f = open(hyper_params['data_base'] + 'test_te.csv')\n",
    "    lines_test_te = f.readlines()[1:]\n",
    "    \n",
    "    unique_sid = list()\n",
    "    with open(hyper_params['data_base'] + 'unique_sid.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            unique_sid.append(line.strip())\n",
    "    num_items = len(unique_sid)\n",
    "    \n",
    "    file_write(hyper_params['log_file'], \"Data Files loaded!\")\n",
    "\n",
    "    train_reader = DataReader(hyper_params, lines_train, None, num_items, True)\n",
    "    val_reader = DataReader(hyper_params, lines_val_tr, lines_val_te, num_items, False)\n",
    "    test_reader = DataReader(hyper_params, lines_test_tr, lines_test_te, num_items, False)\n",
    "\n",
    "    return train_reader, val_reader, test_reader, num_items\n",
    "\n",
    "class DataReader:\n",
    "    def __init__(self, hyper_params, a, b, num_items, is_training):\n",
    "        self.hyper_params = hyper_params\n",
    "        self.batch_size = hyper_params['batch_size']\n",
    "        \n",
    "        num_users = 0\n",
    "        min_user = 1000000000000000000000000 # Infinity\n",
    "        unique_users = set()\n",
    "        for line in a:\n",
    "            line = line.strip().split(\",\")\n",
    "            unique_users.add(int(line[0]))\n",
    "#             num_users = max(num_users, int(line[0]))\n",
    "#             min_user = min(min_user, int(line[0]))\n",
    "            \n",
    "#         num_users = num_users - min_user + 1\n",
    "        \n",
    "        self.num_users = len(unique_users)\n",
    "        self.id2idx = dict(zip(unique_users, range(self.num_users)))\n",
    "        self.min_user = min_user\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        self.data_train = a\n",
    "        self.data_test = b\n",
    "        self.is_training = is_training\n",
    "        self.all_users = []\n",
    "        \n",
    "        self.prep()\n",
    "        self.number()\n",
    "\n",
    "    def prep(self):\n",
    "        print(f'num_users:{self.num_users}, len data_train:{len(self.data_train)}')\n",
    "        self.data = []\n",
    "        for i in range(self.num_users): self.data.append([])\n",
    "            \n",
    "        for i in tqdm(range(len(self.data_train))):\n",
    "            line = self.data_train[i]\n",
    "            line = line.strip().split(\",\")\n",
    "            self.data[self.id2idx[int(line[0])]].append([ int(line[1]), 1 ])\n",
    "        \n",
    "        if self.is_training == False:\n",
    "            self.data_te = []\n",
    "            for i in range(self.num_users): self.data_te.append([])\n",
    "                \n",
    "            for i in tqdm(range(len(self.data_test))):\n",
    "                line = self.data_test[i]\n",
    "                line = line.strip().split(\",\")\n",
    "                self.data_te[self.id2idx[int(line[0])]].append([ int(line[1]), 1 ])\n",
    "        \n",
    "    def number(self):\n",
    "        self.num_b = int(min(len(self.data), self.hyper_params['number_users_to_keep']) / self.batch_size)\n",
    "    \n",
    "    def iter(self):\n",
    "        users_done = 0\n",
    "\n",
    "        x_batch = []\n",
    "        \n",
    "        user_iterate_order = list(range(len(self.data)))\n",
    "        \n",
    "        # Randomly shuffle the training order\n",
    "        np.random.shuffle(user_iterate_order)\n",
    "        \n",
    "        for user in user_iterate_order:\n",
    "\n",
    "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
    "            users_done += 1\n",
    "            \n",
    "            # TODO leave len(self.data[user]) - 1\n",
    "            y_batch_s = torch.zeros(self.batch_size, len(self.data[user]) - 1, self.num_items)\n",
    "            if is_cuda_available: y_batch_s = y_batch_s.cuda()\n",
    "            \n",
    "            if self.hyper_params['loss_type'] == 'predict_next':\n",
    "                for timestep in range(len(self.data[user]) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in [ self.data[user][timestep + 1] ] ]), 1.0\n",
    "                    )\n",
    "                \n",
    "            elif self.hyper_params['loss_type'] == 'next_k':\n",
    "                for timestep in range(len(self.data[user]) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
    "                    )\n",
    "                \n",
    "            elif self.hyper_params['loss_type'] == 'postfix':\n",
    "                for timestep in range(len(self.data[user]) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in self.data[user][timestep + 1:] ]), 1.0\n",
    "                    )\n",
    "            \n",
    "            x_batch.append([ i[0] for i in self.data[user][:-1] ])\n",
    "            \n",
    "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
    "            \n",
    "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False)\n",
    "                x_batch = []\n",
    "\n",
    "    def iter_eval(self):\n",
    "\n",
    "        x_batch = []\n",
    "        test_movies, test_movies_r = [], []\n",
    "        \n",
    "        users_done = 0\n",
    "        \n",
    "        for user in range(len(self.data)):\n",
    "            \n",
    "            users_done += 1\n",
    "            if users_done > self.hyper_params['number_users_to_keep']: break\n",
    "            \n",
    "            if self.is_training == True: \n",
    "                split = float(self.hyper_params['history_split_test'][0])\n",
    "                base_predictions_on = self.data[user][:int(split * len(self.data[user]))]\n",
    "                heldout_movies = self.data[user][int(split * len(self.data[user])):]\n",
    "            else:\n",
    "                base_predictions_on = self.data[user]\n",
    "                heldout_movies = self.data_te[user]\n",
    "            \n",
    "            y_batch_s = torch.zeros(self.batch_size, len(base_predictions_on) - 1, self.num_items)\n",
    "            if is_cuda_available: y_batch_s = y_batch_s.cuda()\n",
    "            \n",
    "            if self.hyper_params['loss_type'] == 'predict_next':\n",
    "                for timestep in range(len(base_predictions_on) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in [ base_predictions_on[timestep + 1] ] ]), 1.0\n",
    "                    )\n",
    "                \n",
    "            elif self.hyper_params['loss_type'] == 'next_k':\n",
    "                for timestep in range(len(base_predictions_on) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:][:self.hyper_params['next_k']] ]), 1.0\n",
    "                    )\n",
    "                \n",
    "            elif self.hyper_params['loss_type'] == 'postfix':\n",
    "                for timestep in range(len(base_predictions_on) - 1):\n",
    "                    y_batch_s[len(x_batch), timestep, :].scatter_(\n",
    "                        0, LongTensor([ i[0] for i in base_predictions_on[timestep + 1:] ]), 1.0\n",
    "                    )\n",
    "            \n",
    "            test_movies.append([ i[0] for i in heldout_movies ])\n",
    "            test_movies_r.append([ i[1] for i in heldout_movies ])\n",
    "            x_batch.append([ i[0] for i in base_predictions_on[:-1] ])\n",
    "            \n",
    "            if len(x_batch) == self.batch_size: # batch_size always = 1\n",
    "                \n",
    "                yield Variable(LongTensor(x_batch)), Variable(y_batch_s, requires_grad=False), test_movies, test_movies_r\n",
    "                x_batch = []\n",
    "                test_movies, test_movies_r = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, reader, hyper_params, is_train_set):\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['loss'] = 0.0\n",
    "    Ks = [10, 100]\n",
    "    for k in Ks: \n",
    "        metrics['NDCG@' + str(k)] = 0.0\n",
    "        metrics['Rec@' + str(k)] = 0.0\n",
    "        metrics['Prec@' + str(k)] = 0.0\n",
    "\n",
    "    batch = 0\n",
    "    total_users = 0.0\n",
    "    \n",
    "    # For plotting the results (seq length vs. NDCG@100)\n",
    "    len_to_ndcg_at_100_map = {}\n",
    "\n",
    "    for x, y_s, test_movies, test_movies_r in reader.iter_eval():\n",
    "        batch += 1\n",
    "        if is_train_set == True and batch > hyper_params['train_cp_users']: break\n",
    "\n",
    "        decoder_output, z_mean, z_log_sigma = model(x)\n",
    "        \n",
    "        metrics['loss'] += criterion(decoder_output, z_mean, z_log_sigma, y_s, 0.2).data.item()\n",
    "        \n",
    "        # Making the logits of previous items in the sequence to be \"- infinity\"\n",
    "        decoder_output = decoder_output.data\n",
    "        x_scattered = torch.zeros(decoder_output.shape[0], decoder_output.shape[2])\n",
    "        if is_cuda_available: x_scattered = x_scattered.cuda()\n",
    "        x_scattered[0, :].scatter_(0, x[0].data, 1.0)\n",
    "        last_predictions = decoder_output[:, -1, :] - (torch.abs(decoder_output[:, -1, :] * x_scattered) * 100000000)\n",
    "        \n",
    "        for batch_num in range(last_predictions.shape[0]): # batch_num is ideally only 0, since batch_size is enforced to be always 1\n",
    "            predicted_scores = last_predictions[batch_num]\n",
    "            actual_movies_watched = test_movies[batch_num]\n",
    "            actual_movies_ratings = test_movies_r[batch_num]\n",
    "                    \n",
    "            # Calculate NDCG\n",
    "            _, argsorted = torch.sort(-1.0 * predicted_scores)\n",
    "            for k in Ks:\n",
    "                best, now_at, dcg, hits = 0.0, 0.0, 0.0, 0.0\n",
    "                \n",
    "                rec_list = list(argsorted[:k].cpu().numpy())\n",
    "                for m in range(len(actual_movies_watched)):\n",
    "                    movie = actual_movies_watched[m]\n",
    "                    now_at += 1.0\n",
    "                    if now_at <= k: best += 1.0 / float(np.log2(now_at + 1))\n",
    "                    \n",
    "                    if movie not in rec_list: continue\n",
    "                    hits += 1.0\n",
    "                    dcg += 1.0 / float(np.log2(float(rec_list.index(movie) + 2)))\n",
    "                \n",
    "                metrics['NDCG@' + str(k)] += float(dcg) / float(best)\n",
    "                metrics['Rec@' + str(k)] += float(hits) / float(len(actual_movies_watched))\n",
    "                metrics['Prec@' + str(k)] += float(hits) / float(k)\n",
    "                \n",
    "                # Only for plotting the graph (seq length vs. NDCG@100)\n",
    "                if k == 100:\n",
    "                    seq_len = int(len(actual_movies_watched)) + int(x[batch_num].shape[0]) + 1\n",
    "                    if seq_len not in len_to_ndcg_at_100_map: len_to_ndcg_at_100_map[seq_len] = []\n",
    "                    len_to_ndcg_at_100_map[seq_len].append(float(dcg) / float(best))\n",
    "                \n",
    "            total_users += 1.0\n",
    "    \n",
    "    metrics['loss'] = float(metrics['loss']) / float(batch)\n",
    "    metrics['loss'] = round(metrics['loss'], 4)\n",
    "    \n",
    "    for k in Ks:\n",
    "        metrics['NDCG@' + str(k)] = round((100.0 * metrics['NDCG@' + str(k)]) / float(total_users), 4)\n",
    "        metrics['Rec@' + str(k)] = round((100.0 * metrics['Rec@' + str(k)]) / float(total_users), 4)\n",
    "        metrics['Prec@' + str(k)] = round((100.0 * metrics['Prec@' + str(k)]) / float(total_users), 4)\n",
    "        \n",
    "    return metrics, len_to_ndcg_at_100_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(\n",
    "            hyper_params['rnn_size'], hyper_params['hidden_size']\n",
    "        )\n",
    "        nn.init.xavier_normal(self.linear1.weight)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(hyper_params['latent_size'], hyper_params['hidden_size'])\n",
    "        self.linear2 = nn.Linear(hyper_params['hidden_size'], hyper_params['total_items'])\n",
    "        nn.init.xavier_normal(self.linear1.weight)\n",
    "        nn.init.xavier_normal(self.linear2.weight)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(Model, self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "        \n",
    "        self.encoder = Encoder(hyper_params)\n",
    "        self.decoder = Decoder(hyper_params)\n",
    "        \n",
    "        # Since we don't need padding, our vocabulary size = \"hyper_params['total_items']\" and not \"hyper_params['total_items'] + 1\"\n",
    "        self.item_embed = nn.Embedding(hyper_params['total_items'], hyper_params['item_embed_size'])\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            hyper_params['item_embed_size'], hyper_params['rnn_size'], \n",
    "            batch_first = True, num_layers = 1\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(hyper_params['hidden_size'], 2 * hyper_params['latent_size'])\n",
    "        nn.init.xavier_normal(self.linear1.weight)\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        temp_out = self.linear1(h_enc)\n",
    "        \n",
    "        mu = temp_out[:, :self.hyper_params['latent_size']]\n",
    "        log_sigma = temp_out[:, self.hyper_params['latent_size']:]\n",
    "        \n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
    "        if is_cuda_available: std_z = std_z.cuda()\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_log_sigma = log_sigma\n",
    "\n",
    "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_shape = x.shape                                      # [bsz x seq_len] = [1 x seq_len]\n",
    "        x = x.view(-1)                                          # [seq_len]\n",
    "        \n",
    "        x = self.item_embed(x)                                  # [seq_len x embed_size]\n",
    "        x = x.view(in_shape[0], in_shape[1], -1)                # [1 x seq_len x embed_size]\n",
    "        \n",
    "        rnn_out, _ = self.gru(x)                                # [1 x seq_len x rnn_size]\n",
    "        rnn_out = rnn_out.view(in_shape[0] * in_shape[1], -1)   # [seq_len x rnn_size]\n",
    "        \n",
    "        enc_out = self.encoder(rnn_out)                         # [seq_len x hidden_size]\n",
    "        sampled_z = self.sample_latent(enc_out)                 # [seq_len x latent_size]\n",
    "        \n",
    "        dec_out = self.decoder(sampled_z)                       # [seq_len x total_items]\n",
    "        dec_out = dec_out.view(in_shape[0], in_shape[1], -1)    # [1 x seq_len x total_items]\n",
    "                              \n",
    "        return dec_out, self.z_mean, self.z_log_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss\n",
    "\n",
    "$$ Loss \\; = \\; \\sum_{u \\in U} Loss_u $$ <br>\n",
    "$$ Loss_u \\; = \\; \\beta * KL( \\, \\phi(z \\vert x) \\, \\Vert \\, {\\rm I\\!N(0, I)} \\, ) \\; - \\; log( \\, P_{\\phi}(g_{\\theta}(x)) \\, ) $$ <br>\n",
    "$ g_{\\theta}(.)$ is the encoder ; $P_{\\phi}(.)$ is the decoded distribution; $ \\beta $ is the anneal factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAELoss(torch.nn.Module):\n",
    "    def __init__(self, hyper_params):\n",
    "        super(VAELoss,self).__init__()\n",
    "        self.hyper_params = hyper_params\n",
    "\n",
    "    def forward(self, decoder_output, mu_q, logvar_q, y_true_s, anneal):\n",
    "        # Calculate KL Divergence loss\n",
    "        kld = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1), -1))\n",
    "    \n",
    "        # Calculate Likelihood\n",
    "        dec_shape = decoder_output.shape # [batch_size x seq_len x total_items] = [1 x seq_len x total_items]\n",
    "\n",
    "        decoder_output = F.log_softmax(decoder_output, -1)\n",
    "        num_ones = float(torch.sum(y_true_s[0, 0]))\n",
    "        \n",
    "        likelihood = torch.sum(\n",
    "            -1.0 * y_true_s.view(dec_shape[0] * dec_shape[1], -1) * \\\n",
    "            decoder_output.view(dec_shape[0] * dec_shape[1], -1)\n",
    "        ) / (float(self.hyper_params['batch_size']) * num_ones)\n",
    "        \n",
    "        final = (anneal * kld) + (likelihood)\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(reader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    batch = 0\n",
    "    batch_limit = int(train_reader.num_b)\n",
    "    total_anneal_steps = 200000\n",
    "    anneal = 0.0\n",
    "    update_count = 0.0\n",
    "    anneal_cap = 0.2\n",
    "\n",
    "    for x, y_s in reader.iter():\n",
    "        batch += 1\n",
    "        \n",
    "        # Empty the gradients\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        decoder_output, z_mean, z_log_sigma = model(x)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss = criterion(decoder_output, z_mean, z_log_sigma, y_s, anneal)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "        \n",
    "        # Anneal logic\n",
    "        if total_anneal_steps > 0:\n",
    "            anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "        else:\n",
    "            anneal = anneal_cap\n",
    "        update_count += 1.0\n",
    "        \n",
    "        # Logging mechanism\n",
    "        if (batch % hyper_params['batch_log_interval'] == 0 and batch > 0) or batch == batch_limit:\n",
    "            div = hyper_params['batch_log_interval']\n",
    "            if batch == batch_limit: div = (batch_limit % hyper_params['batch_log_interval']) - 1\n",
    "            if div <= 0: div = 1\n",
    "\n",
    "            cur_loss = (total_loss.item() / div)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            ss = '| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | loss {:5.4f}'.format(\n",
    "                    epoch, batch, batch_limit, (elapsed * 1000) / div, cur_loss\n",
    "            )\n",
    "            \n",
    "            file_write(hyper_params['log_file'], ss)\n",
    "\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started reading data file\n",
      "Data Files loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5281/429847 [00:00<00:08, 52807.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users:4525, len data_train:429847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429847/429847 [00:01<00:00, 275185.35it/s]\n",
      "100%|██████████| 57499/57499 [00:00<00:00, 302725.75it/s]\n",
      "  0%|          | 0/14742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users:748, len data_train:57499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14742/14742 [00:00<00:00, 361849.20it/s]\n",
      "  0%|          | 0/54306 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users:748, len data_train:54306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54306/54306 [00:00<00:00, 161113.31it/s]\n",
      "100%|██████████| 13970/13970 [00:00<00:00, 394264.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Simulation run on: 2022-05-21 18:42:38.419508\n",
      "\n",
      "\n",
      "Data reading complete!\n",
      "Number of train batches: 4525\n",
      "Number of validation batches:  748\n",
      "Number of test batches:  748\n",
      "Total Items: 3478\n",
      "\n",
      "Model(\n",
      "  (encoder): Encoder(\n",
      "    (linear1): Linear(in_features=200, out_features=150, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (linear1): Linear(in_features=64, out_features=150, bias=True)\n",
      "    (linear2): Linear(in_features=150, out_features=3478, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      "  (item_embed): Embedding(3478, 256)\n",
      "  (gru): GRU(256, 200, batch_first=True)\n",
      "  (linear1): Linear(in_features=150, out_features=128, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "\n",
      "Model Built!\n",
      "Starting Training...\n",
      "\n",
      "| epoch   1 |  1000/ 4525 batches | ms/batch 17.28 | loss 681.2001\n",
      "| epoch   1 |  2000/ 4525 batches | ms/batch 16.86 | loss 616.6078\n",
      "| epoch   1 |  3000/ 4525 batches | ms/batch 16.52 | loss 575.7214\n",
      "Exiting from training early\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a90f214c4706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;31m# Checking metrics for the test set on best saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_to_ndcg_at_100_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m# Plot sequence length vs NDCG@100 graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1791defa1040>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, criterion, reader, hyper_params, is_train_set)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlen_to_ndcg_at_100_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_movies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_movies_r\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_train_set\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_cp_users'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b6a1f810131c>\u001b[0m in \u001b[0;36miter_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_predictions_on\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     y_batch_s[len(x_batch), timestep, :].scatter_(\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_predictions_on\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimestep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     )\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train It..\n",
    "train_reader, val_reader, test_reader, total_items = load_data(hyper_params)\n",
    "hyper_params['total_items'] = total_items\n",
    "hyper_params['testing_batch_limit'] = test_reader.num_b\n",
    "\n",
    "file_write(hyper_params['log_file'], \"\\n\\nSimulation run on: \" + str(dt.datetime.now()) + \"\\n\\n\")\n",
    "file_write(hyper_params['log_file'], \"Data reading complete!\")\n",
    "file_write(hyper_params['log_file'], \"Number of train batches: {:4d}\".format(train_reader.num_b))\n",
    "file_write(hyper_params['log_file'], \"Number of validation batches: {:4d}\".format(val_reader.num_b))\n",
    "file_write(hyper_params['log_file'], \"Number of test batches: {:4d}\".format(test_reader.num_b))\n",
    "file_write(hyper_params['log_file'], \"Total Items: \" + str(total_items) + \"\\n\")\n",
    "\n",
    "model = Model(hyper_params)\n",
    "if is_cuda_available: \n",
    "    print('SENDING MODEL TO CUDA...')\n",
    "    model.cuda()\n",
    "\n",
    "criterion = VAELoss(hyper_params)\n",
    "\n",
    "if hyper_params['optimizer'] == 'adagrad':\n",
    "    optimizer = torch.optim.Adagrad(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay'], lr = hyper_params['learning_rate']\n",
    "    )\n",
    "elif hyper_params['optimizer'] == 'adadelta':\n",
    "    optimizer = torch.optim.Adadelta(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
    "    )\n",
    "elif hyper_params['optimizer'] == 'adam':\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
    "    )\n",
    "elif hyper_params['optimizer'] == 'rmsprop':\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        model.parameters(), weight_decay=hyper_params['weight_decay']\n",
    "    )\n",
    "\n",
    "file_write(hyper_params['log_file'], str(model))\n",
    "file_write(hyper_params['log_file'], \"\\nModel Built!\\nStarting Training...\\n\")\n",
    "\n",
    "best_val_ndcg = None\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, hyper_params['epochs'] + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train(train_reader)\n",
    "        \n",
    "        # Calulating the metrics on the train set\n",
    "        metrics, _ = evaluate(model, criterion, train_reader, hyper_params, True)\n",
    "        string = \"\"\n",
    "        for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
    "        string += ' (TRAIN)'\n",
    "    \n",
    "        # Calulating the metrics on the validation set\n",
    "        metrics, _ = evaluate(model, criterion, val_reader, hyper_params, False)\n",
    "        string2 = \"\"\n",
    "        for m in metrics: string2 += \" | \" + m + ' = ' + str(metrics[m])\n",
    "        string2 += ' (VAL)'\n",
    "\n",
    "        ss  = '-' * 89\n",
    "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
    "        ss += string\n",
    "        ss += '\\n'\n",
    "        ss += '-' * 89\n",
    "        ss += '\\n| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time))\n",
    "        ss += string2\n",
    "        ss += '\\n'\n",
    "        ss += '-' * 89\n",
    "        file_write(hyper_params['log_file'], ss)\n",
    "        \n",
    "        if not best_val_ndcg or metrics['NDCG@100'] >= best_val_ndcg:\n",
    "            with open(hyper_params['model_file_name'], 'wb') as f: torch.save(model, f)\n",
    "            best_val_ndcg = metrics['NDCG@100']\n",
    "\n",
    "except KeyboardInterrupt: print('Exiting from training early')\n",
    "\n",
    "# Plot Traning graph\n",
    "f = open(model.hyper_params['log_file'])\n",
    "lines = f.readlines()\n",
    "lines.reverse()\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for line in lines:\n",
    "    if line[:10] == 'Simulation' and len(train) > 1: break\n",
    "    elif line[:10] == 'Simulation' and len(train) <= 1: train, test = [], []\n",
    "        \n",
    "    if line[2:5] == 'end' and line[-5:-2] == 'VAL': test.append(line.strip().split(\"|\"))\n",
    "    elif line[2:5] == 'end' and line[-7:-2] == 'TRAIN': train.append(line.strip().split(\"|\"))\n",
    "\n",
    "train.reverse()\n",
    "test.reverse()\n",
    "\n",
    "train_ndcg = []\n",
    "test_ndcg = []\n",
    "test_loss, train_loss = [], []\n",
    "\n",
    "for i in train:\n",
    "    for metric in i:\n",
    "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
    "            train_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
    "        if metric.split(\"=\")[0] == \" loss \":\n",
    "            train_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
    "\n",
    "total, avg_runtime = 0.0, 0.0\n",
    "for i in test:\n",
    "    avg_runtime += float(i[2].split(\" \")[2][:-1])\n",
    "    total += 1.0\n",
    "    \n",
    "    for metric in i:\n",
    "        if metric.split(\"=\")[0] == \" NDCG@100 \":\n",
    "            test_ndcg.append(float(metric.split('=')[1].split(' ')[1]))\n",
    "        if metric.split(\"=\")[0] == \" loss \":\n",
    "            test_loss.append(float(metric.split(\"=\")[1].split(' ')[1]))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "ax1.set_title(hyper_params[\"project_name\"],fontweight=\"bold\", size=20)\n",
    "ax1.plot(test_ndcg, 'b-')\n",
    "ax1.set_xlabel('Epochs', fontsize = 20.0)\n",
    "ax1.set_ylabel('NDCG@100', color='b', fontsize = 20.0)\n",
    "ax1.tick_params('y', colors='b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(test_loss, 'r--')\n",
    "ax2.set_ylabel('Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "fig.tight_layout()\n",
    "if not os.path.isdir(\"saved_plots/\"): os.mkdir(\"saved_plots/\")\n",
    "fig.savefig(\"saved_plots/learning_curve_\" + hyper_params[\"project_name\"] + \".pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Checking metrics for the test set on best saved model\n",
    "with open(hyper_params['model_file_name'], 'rb') as f: model = torch.load(f)\n",
    "metrics, len_to_ndcg_at_100_map = evaluate(model, criterion, test_reader, hyper_params, False)\n",
    "\n",
    "# Plot sequence length vs NDCG@100 graph\n",
    "plot_len_vs_ndcg(len_to_ndcg_at_100_map)\n",
    "\n",
    "string = \"\"\n",
    "for m in metrics: string += \" | \" + m + ' = ' + str(metrics[m])\n",
    "\n",
    "ss  = '=' * 89\n",
    "ss += '\\n| End of training'\n",
    "ss += string + \" (TEST)\"\n",
    "ss += '\\n'\n",
    "ss += '=' * 89\n",
    "file_write(hyper_params['log_file'], ss)\n",
    "print(\"average runtime per epoch =\", round(avg_runtime / float(total), 4), \"s\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "223px",
    "width": "193px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Notebook contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
